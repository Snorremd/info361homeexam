\subsection{Activity Theory and HRI}
In this section we will see how Activity Theory can inform the design of sociability in robots. To really understand how Activity Theory can be used in HRI a short description of various Activity Theory concepts are in order.

\subsubsection{Activity Theory}

Activity Theory is one of several post-cognitivist theories. In \citetitle{Kaptelinin2012}, \textcite{Kaptelinin2012} give a thorough introduction to the fundamentals of Activity Theory and how the theory relates to HCI. Activity Theory builds on the sociocultural perspective from Russian psychology. The sociocultural perspective holds that the mind is not a separate entity from the world. This stands in contrast to earlier cognitive perspectives where the mind and world is considered separate entities, and culture and society are merely external factors affecting the mind.

Looking at the origin of the psyche Leontiev identified the processes of activity as those processes through which an active relation of the subject to reality is realized \parencite{Kaptelinin2012}. Activity thus refers to the interaction between subject and object. In Activity Theory, however, activity refers to those subject-object interactions were the object has the status of a motive \parencite{Kaptelinin2012}. Subject-object interactions are not restricted to a flat dimension, but can be organized into a hierarchy of higher and lower-level objects. \textcite{Kaptelinin2012} examplify this by the activity of writing a novel. Here the different objects are the individual keys on the keyboard, the words being written and the novel itself. It is human needs, cultural or physical, that motivate the activities. 

Each individual activity can be divided into a hierarchical structure consisting of the activity itself, goals (and sub-goals), as well as operations. One separates between two types of objects, objects at which activities are directed and activities which attract individuals. An activity consists of a number of steps. The objects which are not directly directed at the activity make up the goals to these steps. The steps are called actions. For the novel example the words would be the objects which make up the goals of the action. ``\textit{Operations are routine processes providing an adjustment of an action to the ongoing situation. They are oriented towards the conditions under which the subject is attaining a goal.}'' \parencite[][27]{Kaptelinin2012}. An example of an operation could be typing a word in a word editor. Depending on the subject, an action could be transformed into an operation. For example, for a novice computer-user typing a letter might be a conscious action, but for a experienced typer, typing a letter would most likely be an automated operation.

An important notion in Activity Theory is the concept of agency. \textcite[][37]{Kaptelinin2012} define human agency as ``\textit{[\dots] the ability and the need to act}''. It is this definition, the authors state, that separates the definition of the human ability to act from the terms basic meaning which is the ability to produce an effect. In this way the human action is defined as the ability to produce an effect according to some intention \cite{Kaptelinin2012}. The authors define six types of agents: natural things, cultural things, non-human living beings, human beings, and social entities. They also provide four types of agency: conditional agency (acting according to biological needs, performing unintentional actions etc.), need-based agency (acting according to own cultural needs) and delegated agency (realizing intentions of other entities). Table 3.1 in \citetitle{Kaptelinin2012} provide a table which shows which kinds of agencies each type of agent can have.

\subsubsection{Robots as agents}

How can Activity Theory inform HRI? It seems as though Activity Theory might be able to provide much insight to the field of HRI. The notion of agency is especially relevant for social robotics. How does a social robot choose which activities to perform? And how does the robot know which actions to take to accomplish this activity? In \citetitle{Scholtz2003robot} \textcite{Scholtz2003robot} propose new possible models of HRI that builds on Norman's model of human-computer interaction. In the proposed models the goals are initially given by humans (similar to delegated agency), and the robot then performs certain actions to realize those goals. It seems that Activity Theory would also be a good fit for this kind of analysis. 

The diagram of agency \parencite{Kaptelinin2012} can give valuable input. It is not clear as which type of agent a social robot would be classified. It could be theorized that it would be possible to design a social robot capable of exhibiting all the three types of agency (conditional, need-based, and delegated). This would place the robot in the same class of agency as humans. Robots today mostly possess the delegated and conditional forms of agency, i.e. they realize the intentions of human beings or they produce unintentional effects. I argue that social robots need to have a form of need-based agency to be truly social. Sociability in biological life, it could be argued, exist to increase the chances of survival. But sociability could also be seen as a cultural need, a need to fit into society. A robot without need-based agency would not have a need to be social, and would in this case only be social on account of delegated agency (i.e. to be a social partner for a human being).

The need to survive, part of the need-based agency, also apply to robots.
\begin{quote}
Robots not only have to carry out their tasks, they also have
to survive in the human environment. The ability for robots to adapt and learn in their environment is fundamental given that human designers cannot predict all possible circumstances and challenges a robot will encounter during its lifetime. \parencite[][183]{Breazeal2004robot}.
\end{quote}
Also here can Activity Theory and its origins, sociocultural psychology, give invaluable insight. According to \textcite{Kaptelinin2012} Vygostky holds that psychological functions do not emerge as a functions of an individual, but rather emerge as an inter-psychological functions shared between an individual and other people. This perspective on the development of the mind could be applied to social robots and the learning problem. By designing the robot so that its ``psychological'' functions can develop by interacting  with a human being, a social robot would be able to learn how to ``navigate'' the human world over time. Unforeseen circumstances and challenges would be solved by the robot interacting with a human who could guide the robot through the task.

The concepts of activity, actions and operations are also useful in the design of robots for HRI. Given a robot with agency, one could analyze the sort of actions a robot would have to take in order to fulfill a higher-level goal (i.e. motivation) and how the robot could be able to choose the right actions given an activity. Given a motivation, for instance to get to know someone, what would be the actions required to achieve the motivation of the activity? And how would the robot know which actions to take in order to achieve the desired goals? In context of robots it is hard to see how the concept of operations would work. It is possible to imagine a robot with sufficiently intelligent learning algorithms that would be capable of transforming some actions to operations. For example could the action of adjusting its position to avoid collision with objects and other persons when walking down the street be a conscious action the first few times, but then be transformed into an operation as the learning algorithms kick in and the robot knows how to avoid obstacles. The successful implementation of the Activity Theoretical theory of cognition thus relies on the ability to emulate the development of human mental development.



\subsection{Distributed Cognition}

Where traditional cognitive theories set the individual as the boundary of cognition, the theory of distributed cognition ``\textit{[\dots]extends the reach of what is considered cognitive beyond the individual to encompass interactions between people and with re- sources and materials in the environment.}'' \parencite[][175]{Hollan2000distributedcognition}. Cognitive Distribution have three tenets. \textcite[][175]{Hollan2000distributedcognition} state that ``\textit{In distributed cognition, one expects to find a system that can dynamically configure itself to bring subsystems into coordination to accomplish various functions.}''. In Distributed Cognition the elements of the system (individuals or computer systems) are not delimited by spatial collocatedness, but rather by their functional relationships. \textcite{Hollan2000distributedcognition} go on to argue that social organization (of individuals and groups) can be viewed as a form of cognitive architecture since social organization determine the way in which information flows through a group. The second tenet of distributed cognition, which this theory share with phenomenology and Activity Theory, is that cognition is embodied. ``From the perspective of distributed cognition, the organization of mind both in development and in operation is an emergent property of interactions among internal and external resources. In this view, the human body and the material world take on central rather than peripheral roles.'' \parencite[][178]{Hollan2000distributedcognition}. The last tenet in short is that the study of cognition and study of culture is inseparable seeing as how agents (people or other entities) live in cultural environments.

The three tenets of Distributed Cognition leads to the requirement of a new kind of cognitive ethnography where the functional properties of distributed cognitive systems are studied \parencite{Hollan2000distributedcognition}. The authors explain the cognitive ethnography methodology which is centered around events.
\begin{quote}The theory holds that cognitive activity is constructed from both internal and external resources, and that the meanings of actions are grounded in the context of activity. This means that in order to understand situated human cognition, it is not enough to know how the mind processes information. It is also necessary to know how the information to be processed is arranged in the material and social world. \parencite[][179]{Hollan2000distributedcognition}.
\end{quote}
Based on this observation the authors present a research framework for studying cognitive science and the design of new types of HCI. The framework consist of five elements: Distributed Cognition, Ethnography, Workplaces, Experiment, Work Materials. The theory of Distributed cognition can identify a set of core principles that identify classes of phenomena \parencite{Hollan2000distributedcognition}. (Cognitive) ethnography has tools of observation and analysis, but may be constrained by the available data. In such a case experiments may help to collect more data. Distributed cognition, ethnography and experiments work together to inform the design of work materials. Because the introduction of new work items change the workplace in which they are introduced, \textcite{Hollan2000distributedcognition} state, such introductions may be considered ethnographic experiments themselves. 

\subsubsection{Robots in the workspace}

So how can the theory of Distributed Cognition and the integrated research framework proposed by \textcite{Hollan2000distributedcognition} be of benefit to research of HRI and the design of robots? One example of research on HRI based on Distributed Cognition and using ethnographic studies will help answer this question. In \citetitle{Forlizzi2008hri} \textcite{Forlizzi2008hri} study how autonomous robots affect two organizations' workflows and the products or services they produce. This study thereby fit straight into the theoretical framework of \parencite{Hollan2000distributedcognition}. Introducing robots into a workspace might lead to big changes in the workspace. \textcite{Forlizzi2008hri} discovered four dimensions: work-flow, political, social/emtional, and environmental, which varied for different roles in the organization. The work-flow would for example be rated lower by staff with a low interruptibility-factor because the robots would cause interruptions in their workday thereby reducing their work-flow. If we refer back to the paper by \textcite{Yanco2004robot} the ``INTERACTION-ROLE'' category would here be relevant as the nurses interaction role with the new robots affected their ability to focus on their work.

When designing robots meant to be introduced into a workspace it seems to be necessary to do a thorough ethnographic study to identify the properties of the system (workplace) and the way in which the cognition is distributed between different workers and tools. \textcite[][181]{Hollan2000distributedcognition} state that one core principle of Distributed Cognition is that ``\textit{people off-load cognitive effort to the environment whenever practical}''. In a study on robots in the workspace this principle could be one item of study. In the case of the automated delivery robot studied by \textcite{Forlizzi2008hri}, it would be interesting to investigate how the delivery robot could affect the cognitive effort of the different types of workers (cleaning personnel, nurses etc.). Because ethnographic studies are limited in the data they can provide the researchers, sometimes it is necessary to perform experiments.

Controlled experiments had their origins in the natural sciences, but also the fields of psychology and social sciences has seen use of this research method. In \citetitle{blandford2008controlled} \textcite{blandford2008controlled} explain how controlled experiments can be performed to test an interface, styles of interaction and to understand cognition when interacting with systems. Such experiments could be used to test the effects of introducing social robots into a work process.

In the case of social robots the process of study and design would be very complex. Before one could integrate social robots into a workplace one would have to perform thorough studies. Ethnographic studies to map the distributed cognition, i.e. the work-flow and flow of information in the workplace would go a long way to help inform the design of a social robot to be integrated into a workplace. There could for example be instances where the flow of information is slow because of high amounts of information needing to be processed. By identifying areas of weaknesses in the shared cognition that could be strengthened by the help of robotics, without causing disturbances in the existing system, it would be possible to introduce social robots into a workplace. It would also be possible to do controlled experiments in which a style of interaction, say interacting with another human being versus interacting with a robot, would be tested to determine which produced the best performance.

\subsection{Interaction techniques}

This paper have so far talked about how Activity Theory and theory of Distributed Cognition can be used to help inform the design of social robots. This section will look at different interaction techniques and how they can be used in the design of social robots.

\subsubsection{Proxemic Interacion}

Earlier in this paper Proxemic Interaction



\subsection{Methods}

When designing and prototyping social robots two different forms of prototyping stands out as especially useful: experience prototyping and user enactments. This section will explore how these methods of prototyping and testing can be used in the design of social robots.

\subsubsection{Experience prototyping}

\textcite[][425]{Buchenau:2000:EP:347642.347802} define an Experience Prototype ``\textit{[\dots]any kind of representation, in any medium, that is designed to understand, explore or communicate what it might be like to engage with the product, space or system we are designing.}''. Experience Prototyping is thus used to convey to the designers or users the kind of experience one would get with a final product with a prototype. So why use Experience Prototyping? According to \textcite{Buchenau:2000:EP:347642.347802} the emergence of hybrid artifacts, i.e. artifacts that converge with other systems, software, spaces and services, require new forms of expression of their qualities. The authors identify three activities within the design and development process were they believe Experience Prototyping can be valuable: Understanding existing user experiences and context, exploring and evaluating design ideas, and communicating ideas to an audience \parencite{Buchenau:2000:EP:347642.347802}. It is not immediately clear how one can use such prototyping to build social robots, and one could argue that it would be difficult to design low-fidelity prototypes which would give an experience close to that of an actual robot.

It is possible that Experience Prototyping can be used to some extent. One could argue that the prototyping used in the iterative design-method utilized by \textcite{Kahn2008robot} resemble that of Experience Prototyping. ``\textit{Accordingly, we employed a humanoid robot, ATR’s Robovie, in a laboratory setting, and through controlling some of Robovie’s speech and action from behind the scenes, we created social situations that children and adolescents could engage in.}'' \parencite[][99]{Kahn2008robot}. The goal of the testing in that work was to give the children a sense of how it would be to interact with a social robot. By having the researchers role-play the robot remotely, it is possible to prototype a social robot without having an intelligent or autonomous robot available. As in the \textcite{Kahn2008robot} research, one could prototype different social design patterns for the robot and have users experience how it is to interact with the robot given these patterns.

\subsubsection{User Enactments}

Another form of prototyping is User Enactments. ``User Enactments (UEs) have been developed as a design approach that aids design teams in more successfully investigate radical alterations to technologies’ roles, forms, and behaviors in uncharted design spaces.'' \parencite[][338]{Odom:2012:FFU:2317956.2318008}. Social robots do without doubt represent a radical alteration to existing technology that has a changed role, form and behavior. To investigate how people will perceive social robots it would be beneficial to use User Enactment in the design process. The User Enactment process begins with the design team collecting information (literature and field data), and based on this information create conceptual models and affinity diagrams \parencite{Odom:2012:FFU:2317956.2318008}. The authors do not explain how field data is collected, so here different methods can probably be applied. If one was to design technology for use in a workspace the designer might have to do a cognitive ethnographic study, user observations, surveys etc. Based on this information 100 design concepts are usually made \parencite{Odom:2012:FFU:2317956.2318008}. So what kind of design concepts would fit into the area of social robots? The designers might explore different types of social design patterns. Different kinds of social robots would also be possible concepts.

From 100 design concepts the designers narrow them down in repeated critique sessions using body-storming and by creating scenarios. The remaining set of scenarios are then selected for prototyping, and the designer build ``sets'' to act out the scenarios in \parencite{Odom:2012:FFU:2317956.2318008}. The last part of the User Enactment process revolves around repeatedly piloting the different scenarios with users. If the goal was to act out different social patterns for social robots, one could imagine different scenarios being piloted to investigate the users' feedback to the instantiation of these patterns. One could for example imagine the following social pattern: One individual vocally correcting another person's mistake in front of a group. To investigate how a user would experience this pattern given a social robot as the correcter one could imagine a scenario wherein the robot would vocally correct one of the user's in front of other people. The researchers could then ask the user how she or he felt about it. It would also be possible to iteratively change the scenario by modifying the social pattern in question to investigate how the social robot should behave in the given situation.

\subsubsection{}